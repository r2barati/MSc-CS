{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install torch higher"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdVeF53EZCB4",
        "outputId": "550de275-5255-4f92-edcc-8b72d5d76e0b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Collecting higher\n",
            "  Downloading higher-0.2.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: higher\n",
            "Successfully installed higher-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLxuB3HUWC7o",
        "outputId": "a6dfbf11-0bb9-4eed-fd3d-81ff1f702f95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:03<00:00, 48861590.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Epoch 1/50, Loss: 2.806124448776245\n",
            "Epoch 2/50, Loss: 2.7177078127861023\n",
            "Epoch 3/50, Loss: 2.777456820011139\n",
            "Epoch 4/50, Loss: 2.6378270983695984\n",
            "Epoch 5/50, Loss: 2.644220292568207\n",
            "Epoch 6/50, Loss: 2.805028796195984\n",
            "Epoch 7/50, Loss: 2.6499692797660828\n",
            "Epoch 8/50, Loss: 2.5801976919174194\n",
            "Epoch 9/50, Loss: 2.5858570337295532\n",
            "Epoch 10/50, Loss: 2.771274983882904\n",
            "Epoch 11/50, Loss: 2.8460384607315063\n",
            "Epoch 12/50, Loss: 2.7014419436454773\n",
            "Epoch 13/50, Loss: 2.5644381046295166\n",
            "Epoch 14/50, Loss: 2.5777008533477783\n",
            "Epoch 15/50, Loss: 2.5767248272895813\n",
            "Epoch 16/50, Loss: 2.6235647797584534\n",
            "Epoch 17/50, Loss: 2.463948667049408\n",
            "Epoch 18/50, Loss: 2.3971745371818542\n",
            "Epoch 19/50, Loss: 2.5085909366607666\n",
            "Epoch 20/50, Loss: 2.7464531660079956\n",
            "Epoch 21/50, Loss: 2.562187671661377\n",
            "Epoch 22/50, Loss: 2.6246275901794434\n",
            "Epoch 23/50, Loss: 2.7056201100349426\n",
            "Epoch 24/50, Loss: 2.652585029602051\n",
            "Epoch 25/50, Loss: 2.795331358909607\n",
            "Epoch 26/50, Loss: 2.7620571851730347\n",
            "Epoch 27/50, Loss: 2.5103010535240173\n",
            "Epoch 28/50, Loss: 2.586803913116455\n",
            "Epoch 29/50, Loss: 2.5556886196136475\n",
            "Epoch 30/50, Loss: 2.6441696286201477\n",
            "Epoch 31/50, Loss: 2.639654815196991\n",
            "Epoch 32/50, Loss: 2.732534885406494\n",
            "Epoch 33/50, Loss: 2.685831606388092\n",
            "Epoch 34/50, Loss: 2.756235659122467\n",
            "Epoch 35/50, Loss: 2.734807789325714\n",
            "Epoch 36/50, Loss: 2.70100736618042\n",
            "Epoch 37/50, Loss: 2.750969886779785\n",
            "Epoch 38/50, Loss: 2.638723909854889\n",
            "Epoch 39/50, Loss: 2.8747689723968506\n",
            "Epoch 40/50, Loss: 2.7004750967025757\n",
            "Epoch 41/50, Loss: 2.6008147597312927\n",
            "Epoch 42/50, Loss: 2.739168405532837\n",
            "Epoch 43/50, Loss: 2.7466532588005066\n",
            "Epoch 44/50, Loss: 2.8507522344589233\n",
            "Epoch 45/50, Loss: 2.710550606250763\n",
            "Epoch 46/50, Loss: 2.429724156856537\n",
            "Epoch 47/50, Loss: 2.7332900762557983\n",
            "Epoch 48/50, Loss: 2.7311479449272156\n",
            "Epoch 49/50, Loss: 2.5936686396598816\n",
            "Epoch 50/50, Loss: 2.767680585384369\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import higher\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Define transformations, models (BasicCNN and MAMLModel), and dataloaders\n",
        "\n",
        "# Define the transformation of the dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "full_trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "full_testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define BasicCNN model for CIFAR-100\n",
        "class BasicCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BasicCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
        "        self.fc2 = nn.Linear(512, 100)  # CIFAR-100 has 100 classes\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# DataLoader for CIFAR-100\n",
        "\n",
        "trainloader = DataLoader(full_trainset, batch_size=4, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(full_testset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define MAMLModel for FC100\n",
        "class MAMLModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MAMLModel, self).__init__()\n",
        "        # Define a similar architecture to BasicCNN but adapt it for MAML\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 500)\n",
        "        self.fc2 = nn.Linear(500, 100)  # 100 classes in CIFAR-100\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.pool(self.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# DataLoader for FC100\n",
        "\n",
        "# Randomly select class indices for FC100 split\n",
        "all_classes = list(range(100))\n",
        "random.shuffle(all_classes)\n",
        "fc100_train_classes = all_classes[:60]  # 60 classes for training\n",
        "fc100_val_classes = all_classes[60:80]  # 20 classes for validation\n",
        "fc100_test_classes = all_classes[80:]   # 20 classes for testing\n",
        "\n",
        "def extract_classes(dataset, classes):\n",
        "    class_idx = [idx for idx, (_, label) in enumerate(dataset) if label in classes]\n",
        "    return Subset(dataset, class_idx)\n",
        "\n",
        "# Extract the FC100 subsets\n",
        "trainset_fc100 = extract_classes(full_trainset, fc100_train_classes)\n",
        "valset_fc100 = extract_classes(full_trainset, fc100_val_classes)\n",
        "testset_fc100 = extract_classes(full_testset, fc100_test_classes)\n",
        "\n",
        "# DataLoaders for FC100\n",
        "fc100_trainloader = DataLoader(trainset_fc100, batch_size=5, shuffle=True)\n",
        "fc100_valloader = DataLoader(valset_fc100, batch_size=5, shuffle=True)\n",
        "fc100_testloader = DataLoader(testset_fc100, batch_size=5, shuffle=False)\n",
        "\n",
        "# Complete MAMLModel Definition for FC100 & Setting up the Training Loop for MAML\n",
        "\n",
        "# Define the device for training (GPU if available)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters for MAML\n",
        "inner_lr = 0.01  # Learning rate for task-specific (inner) updates\n",
        "meta_lr = 0.001  # Learning rate for meta (outer) updates\n",
        "num_inner_updates = 5  # Number of gradient updates for task adaptation\n",
        "num_tasks = 4  # Number of tasks per meta-training batch\n",
        "task_batch_size = 10  # Batch size for each task\n",
        "num_epochs = 50  # Number of meta-training epochs\n",
        "\n",
        "# Initialize MAML model and move to device\n",
        "maml_model = MAMLModel().to(device)\n",
        "meta_optimizer = optim.Adam(maml_model.parameters(), lr=meta_lr)\n",
        "\n",
        "# Function to sample tasks for training\n",
        "def sample_tasks(dataset, num_tasks, task_batch_size):\n",
        "    all_indices = list(range(len(dataset)))\n",
        "    random.shuffle(all_indices)\n",
        "    tasks = [all_indices[i:i + task_batch_size] for i in range(0, len(all_indices), task_batch_size)]\n",
        "    return [Subset(dataset, task_indices) for task_indices in tasks[:num_tasks]]\n",
        "\n",
        "# MAML Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    maml_model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    tasks = sample_tasks(trainset_fc100, num_tasks, task_batch_size)\n",
        "\n",
        "    for task in tasks:\n",
        "        task_dataloader = DataLoader(task, batch_size=task_batch_size, shuffle=True)\n",
        "        task_loss = 0.0\n",
        "\n",
        "        # Inner loop for task-specific adaptation\n",
        "        with higher.innerloop_ctx(maml_model, meta_optimizer, copy_initial_weights=False) as (fmodel, diffopt):\n",
        "            for inner_step in range(num_inner_updates):\n",
        "                for data, labels in task_dataloader:\n",
        "                    data, labels = data.to(device), labels.to(device)\n",
        "                    task_prediction = fmodel(data)\n",
        "                    inner_loss = nn.CrossEntropyLoss()(task_prediction, labels)\n",
        "                    diffopt.step(inner_loss)\n",
        "\n",
        "            # Evaluate adapted model on the same task\n",
        "            for data, labels in task_dataloader:\n",
        "                data, labels = data.to(device), labels.to(device)\n",
        "                task_prediction = fmodel(data)\n",
        "                task_loss += nn.CrossEntropyLoss()(task_prediction, labels)\n",
        "\n",
        "        epoch_loss += task_loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/num_tasks}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train BasicCNN on CIFAR-100\n",
        "\n",
        "# Initialize the model\n",
        "basic_cnn = BasicCNN()\n",
        "basic_cnn.to(device)  # Move the model to the appropriate device (GPU/CPU)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(basic_cnn.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Number of epochs for training\n",
        "num_epochs = 10\n",
        "\n",
        "# Lists to track the accuracy and loss for visualization\n",
        "training_accuracies = []\n",
        "training_losses = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = basic_cnn(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate and print statistics for the epoch\n",
        "    epoch_loss = running_loss / len(trainloader)\n",
        "    epoch_accuracy = correct / total\n",
        "    training_accuracies.append(epoch_accuracy)\n",
        "    training_losses.append(epoch_loss)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
        "\n",
        "print('Finished Training BasicCNN on CIFAR-100')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqCABMEDYw2q",
        "outputId": "b18d27d1-2d6e-41a5-8109-cc8330894042"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.6828, Accuracy: 0.1399\n",
            "Epoch 2, Loss: 2.8705, Accuracy: 0.2832\n",
            "Epoch 3, Loss: 2.3937, Accuracy: 0.3837\n",
            "Epoch 4, Loss: 2.0096, Accuracy: 0.4676\n",
            "Epoch 5, Loss: 1.6378, Accuracy: 0.5520\n",
            "Epoch 6, Loss: 1.2481, Accuracy: 0.6449\n",
            "Epoch 7, Loss: 0.8749, Accuracy: 0.7411\n",
            "Epoch 8, Loss: 0.5626, Accuracy: 0.8290\n",
            "Epoch 9, Loss: 0.3973, Accuracy: 0.8761\n",
            "Epoch 10, Loss: 0.2766, Accuracy: 0.9143\n",
            "Finished Training BasicCNN on CIFAR-100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train MAMLModel on FC100\n",
        "\n",
        "# Initialize the MAML model and move it to the device\n",
        "maml_model = MAMLModel().to(device)\n",
        "\n",
        "# Define the meta-optimizer (for outer loop updates)\n",
        "meta_optimizer = optim.Adam(maml_model.parameters(), lr=0.001)\n",
        "\n",
        "# Hyperparameters for MAML training\n",
        "num_epochs = 50  # Total number of epochs for meta-training\n",
        "num_tasks_per_batch = 4  # Number of tasks in each batch\n",
        "task_batch_size = 5  # Number of samples per task\n",
        "num_inner_updates = 5  # Number of gradient updates per task\n",
        "\n",
        "# MAML Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    maml_model.train()\n",
        "    meta_optimizer.zero_grad()\n",
        "\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    # Sample a batch of tasks\n",
        "    tasks = sample_tasks(trainset_fc100, num_tasks_per_batch, task_batch_size)\n",
        "\n",
        "    for task in tasks:\n",
        "        task_dataloader = DataLoader(task, batch_size=task_batch_size, shuffle=True)\n",
        "\n",
        "        # Inner loop: Task-specific adaptation\n",
        "        with higher.innerloop_ctx(maml_model, meta_optimizer, copy_initial_weights=False) as (fmodel, diffopt):\n",
        "            for _ in range(num_inner_updates):\n",
        "                for data, labels in task_dataloader:\n",
        "                    data, labels = data.to(device), labels.to(device)\n",
        "                    task_pred = fmodel(data)\n",
        "                    inner_loss = criterion(task_pred, labels)\n",
        "                    diffopt.step(inner_loss)\n",
        "\n",
        "            # Calculate loss for meta-update\n",
        "            for data, labels in task_dataloader:\n",
        "                data, labels = data.to(device), labels.to(device)\n",
        "                task_pred = fmodel(data)\n",
        "                task_loss = criterion(task_pred, labels)\n",
        "                epoch_loss += task_loss\n",
        "\n",
        "    # Normalize the loss\n",
        "    normalized_loss = epoch_loss / (len(tasks) * len(task_dataloader))\n",
        "\n",
        "    # Perform the meta-update\n",
        "    normalized_loss.backward()  # Backpropagate the normalized loss\n",
        "    meta_optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Meta Loss: {normalized_loss.item():.4f}')\n",
        "\n",
        "print('Finished Training MAMLModel on FC100')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYSAJnp8ZsyS",
        "outputId": "7b07c5c0-681c-4a9c-f3c2-70e3533dca3d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Meta Loss: 1.9493\n",
            "Epoch 2/50, Meta Loss: 2.2649\n",
            "Epoch 3/50, Meta Loss: 2.2767\n",
            "Epoch 4/50, Meta Loss: 1.6969\n",
            "Epoch 5/50, Meta Loss: 1.8486\n",
            "Epoch 6/50, Meta Loss: 1.4934\n",
            "Epoch 7/50, Meta Loss: 1.7497\n",
            "Epoch 8/50, Meta Loss: 1.4155\n",
            "Epoch 9/50, Meta Loss: 1.5759\n",
            "Epoch 10/50, Meta Loss: 1.1527\n",
            "Epoch 11/50, Meta Loss: 1.4723\n",
            "Epoch 12/50, Meta Loss: 1.2955\n",
            "Epoch 13/50, Meta Loss: 1.0371\n",
            "Epoch 14/50, Meta Loss: 0.8746\n",
            "Epoch 15/50, Meta Loss: 0.8525\n",
            "Epoch 16/50, Meta Loss: 0.8417\n",
            "Epoch 17/50, Meta Loss: 0.8182\n",
            "Epoch 18/50, Meta Loss: 0.9042\n",
            "Epoch 19/50, Meta Loss: 0.7868\n",
            "Epoch 20/50, Meta Loss: 1.0086\n",
            "Epoch 21/50, Meta Loss: 1.0629\n",
            "Epoch 22/50, Meta Loss: 0.8419\n",
            "Epoch 23/50, Meta Loss: 0.7817\n",
            "Epoch 24/50, Meta Loss: 0.7791\n",
            "Epoch 25/50, Meta Loss: 1.0613\n",
            "Epoch 26/50, Meta Loss: 0.8706\n",
            "Epoch 27/50, Meta Loss: 1.0826\n",
            "Epoch 28/50, Meta Loss: 1.0197\n",
            "Epoch 29/50, Meta Loss: 0.8525\n",
            "Epoch 30/50, Meta Loss: 0.8660\n",
            "Epoch 31/50, Meta Loss: 0.7903\n",
            "Epoch 32/50, Meta Loss: 1.1831\n",
            "Epoch 33/50, Meta Loss: 0.8032\n",
            "Epoch 34/50, Meta Loss: 1.1107\n",
            "Epoch 35/50, Meta Loss: 1.2771\n",
            "Epoch 36/50, Meta Loss: 0.7769\n",
            "Epoch 37/50, Meta Loss: 0.4049\n",
            "Epoch 38/50, Meta Loss: 0.8457\n",
            "Epoch 39/50, Meta Loss: 1.0492\n",
            "Epoch 40/50, Meta Loss: 0.6693\n",
            "Epoch 41/50, Meta Loss: 0.4668\n",
            "Epoch 42/50, Meta Loss: 1.6334\n",
            "Epoch 43/50, Meta Loss: 1.2387\n",
            "Epoch 44/50, Meta Loss: 0.5799\n",
            "Epoch 45/50, Meta Loss: 0.9535\n",
            "Epoch 46/50, Meta Loss: 0.7760\n",
            "Epoch 47/50, Meta Loss: 0.9454\n",
            "Epoch 48/50, Meta Loss: 1.0253\n",
            "Epoch 49/50, Meta Loss: 1.4152\n",
            "Epoch 50/50, Meta Loss: 0.4416\n",
            "Finished Training MAMLModel on FC100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate both models\n",
        "\n",
        "# Evaluate BasicCNN\n",
        "basic_cnn.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():  # No gradients needed for evaluation\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = basic_cnn(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "cnn_accuracy = correct / total\n",
        "print(f'Accuracy of BasicCNN on CIFAR-100: {cnn_accuracy * 100:.2f}%')\n",
        "\n",
        "# Evaluate MAMLModel on FC100 Test Set\n",
        "\n",
        "# Function to evaluate MAML model\n",
        "def evaluate_maml_model(model, test_dataset, num_tasks, task_batch_size, num_adaptation_steps, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    # Sample tasks for evaluation\n",
        "    tasks = sample_tasks(test_dataset, num_tasks, task_batch_size)\n",
        "\n",
        "    for task in tasks:\n",
        "        task_dataloader = DataLoader(task, batch_size=task_batch_size, shuffle=True)\n",
        "\n",
        "        # Adapt the model to the current task\n",
        "        with higher.innerloop_ctx(model, meta_optimizer, track_higher_grads=False) as (fmodel, diffopt):\n",
        "            for adaptation_step in range(num_adaptation_steps):\n",
        "                for data, labels in task_dataloader:\n",
        "                    data, labels = data.to(device), labels.to(device)\n",
        "                    task_prediction = fmodel(data)\n",
        "                    inner_loss = criterion(task_prediction, labels)\n",
        "                    diffopt.step(inner_loss)\n",
        "\n",
        "            # Evaluate the adapted model on the same task\n",
        "            with torch.no_grad():  # Disable gradient tracking for evaluation\n",
        "                for data, labels in task_dataloader:\n",
        "                    data, labels = data.to(device), labels.to(device)\n",
        "                    task_prediction = fmodel(data)\n",
        "                    _, predicted = torch.max(task_prediction, 1)\n",
        "                    total_correct += (predicted == labels).sum().item()\n",
        "                    total_samples += labels.size(0)\n",
        "\n",
        "    return total_correct / total_samples\n",
        "\n",
        "# Set the parameters for the evaluation\n",
        "num_test_tasks = 20  # Number of test tasks\n",
        "test_task_batch_size = 10  # Batch size per test task\n",
        "num_adaptation_steps = 5  # Adaptation steps during testing\n",
        "\n",
        "# Evaluate the MAMLModel\n",
        "maml_accuracy = evaluate_maml_model(maml_model, testset_fc100, num_test_tasks, test_task_batch_size, num_adaptation_steps, device)\n",
        "print(f'Accuracy of MAMLModel on FC100: {maml_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPJEbTjudcHw",
        "outputId": "09f14cc8-0a52-4de4-86a5-3f47397f2669"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of BasicCNN on CIFAR-100: 38.02%\n",
            "Accuracy of MAMLModel on FC100: 62.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming cnn_accuracy and maml_accuracy are already computed\n",
        "accuracies = [cnn_accuracy * 100, maml_accuracy * 100]  # Convert to percentages\n",
        "models = ['BasicCNN', 'MAMLModel']\n",
        "\n",
        "plt.bar(models, accuracies, color=['blue', 'green'])\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Comparison of Model Accuracies')\n",
        "plt.ylim([0, 100])  # Set the limits of the y-axis to 0-100 for percentage\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "epXyjKKetbXa",
        "outputId": "7cd89909-6dfc-4f6f-f002-a736d831948f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}